{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION\n",
    "In this assignment we try to model the 'Estimated Price' as a linear relation of the other elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSES IN PYTHON\n",
    "Although this might look scary to implement, go about it one function at a time.  \n",
    "Using classes help with keeping track of multiple models and makes your overall code much tidier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self) -> None:\n",
    "       \n",
    "        self.weights: np.ndarray | None = None\n",
    "        self.bias: float | None = None\n",
    "    \n",
    "\n",
    "\n",
    "    ### TODO 1\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \n",
    "        Y_pred = np.ndarray( np.dot(X,self.weights) + self.bias)\n",
    "        return Y_pred\n",
    "\n",
    "\n",
    "\n",
    "    ### TODO 2 \n",
    "    def __loss(self, X: np.ndarray, y: np.ndarray, norm: int) -> tuple:\n",
    "       \n",
    "        predicted = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "        \n",
    "        errors = np.abs(predicted - y) ** norm\n",
    "        loss = (1 / X.shape[0]) * np.sum(errors)\n",
    "\n",
    "        \n",
    "        gradient_base = norm * np.sign(predicted - y) * (np.abs(predicted - y) ** (norm - 1))\n",
    "\n",
    "        dw = (1 / X.shape[0]) * np.dot(X.T, gradient_base)\n",
    "        db = (1 / X.shape[0]) * np.sum(gradient_base)\n",
    "\n",
    "        return loss, dw, db\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, epochs: int = 500, learning_rate: float = 0.01, norm: int = 2, threshold: float = 0.0001) -> None:\n",
    "        \n",
    "\n",
    "        self.weights = np.random.randn(X.shape[1])\n",
    "        self.bias=0\n",
    "        prev_loss=float('inf')\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            y_pred=self.predict(X)\n",
    "            loss = self.__loss(X, y_pred, norm)\n",
    "            \n",
    "            current_loss, dw, db = self.__loss(X, y, norm)\n",
    "            self.weights -= learning_rate * dw\n",
    "            self.bias -= learning_rate * db\n",
    "\n",
    "            if abs(current_loss-prev_loss) <threshold:\n",
    "                break\n",
    "            prev_loss=current_loss\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Converting Data\n",
    "Some features in a dataset are not of numerical type and are either categorical or boolean.  \n",
    "To get past this, we convert the columns by using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "df = pd.read_csv('linear_data.csv')\n",
    "\n",
    "### TODO 4\n",
    "df_onehot=pd.get_dummies(df)\n",
    "\n",
    "X=df_onehot.drop(columns='Estimated Price')\n",
    "y=df_onehot['Estimated Price']\n",
    "\n",
    "X = X.to_numpy() \n",
    "y = y.to_numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-train split\n",
    "Overfitting is one of the biggest problems in machine learning. Overfitting occurs when the model is trained to be very accurate on the given dataset but performs very poorly on a different but similar dataset.\n",
    "To check for overfitting, we split our dataset into test and train sets and check the accuracy/loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score Standardization\n",
    "Since some features might have much higher values than the others, for weights of similar magnitude, the model will mainly focus only on features with large values.  \n",
    "To overcome this, we standardize each feature using Z-Score Standardization so that all features are treated equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score standardization\n",
    "### TODO 5\n",
    "def z_score(X: np.ndarray) -> tuple:\n",
    "    '''\n",
    "    The Z-Score scales data such that its mean is 0 and standard deviation is 1\n",
    "    z-score for a value x in the dataset is (x - mean) / std_dev\n",
    "    (z-score normalization is done over a feature and NOT an entry)\n",
    "    Return the z-score value of all the elements in the set along with the mean and standard deviation of the original set\n",
    "    '''\n",
    "\n",
    "    x_mean = np.mean(X,axis=0)\n",
    "\n",
    "    x_std = np.std(X,mean=0)\n",
    "\n",
    "    x = (X-x_mean)/x_std\n",
    "    return x, x_mean, x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "x_train, x_mean, x_std = z_score(X_train)\n",
    "x_test = (X_test - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3073035637.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.fit(x_train, y_train, epochs: int = 500, learning_rate: float = 0.01, norm: int = 2, threshold: float = 0.0001)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train, epochs=, learning_rate=, norm=, threshold=)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"MSE loss: \", np.mean((y_pred - y_test) ** 2))\n",
    "\n",
    "indices = np.arange(len(y_test))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(indices, y_test, label='True Values', color='blue', marker='o')\n",
    "plt.plot(indices, y_pred, label='Predicted Values', color='red', marker='x')\n",
    "\n",
    "plt.xlabel('Data Points')\n",
    "plt.ylabel('Values')\n",
    "plt.title('True vs Predicted Values')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
